--- 
date: 2021-11-23 
layout: page
current: page
cover:  assets/built/images/logo-python.png
navigation: True
title: 경사하강법 기초 
tags: [python]  
class: post-template
subclass: 'post tag-python'
author: SeongJae Yu
sitemap:
lastmod: 2021-11-23
priority: 0.7
changefreq: 'monthly'
exclude: 'yes'
---

# 경사하강법

* W: Learning Rate * ((Y예측 - Y실제) * X)평균
* b: Learning Rate * ((Y예측 - Y실제) * 1)평균


```python
import numpy as np
import matplotlib.pyplot as plt
```


```python
X = np.random.rand(100)
Y = 0.2 * X * 0.5
```


```python
plt.figure(figsize=(8,6))
plt.scatter(X, Y)
plt.show()
```



![output_4_0](./img/gradient/output_4_0.png)




```python
def plot_prediction(pred, y):
    plt.figure(figsize=(8, 6))
    plt.scatter(X, y)
    plt.scatter(X, pred)
    plt.show()
```

## Gradient Descent 구현

* W: Learning Rate * ((Y예측 - Y실제) * X)평균
* b: Learning Rate * ((Y예측 - Y실제) * 1)평균


```python
W = np.random.uniform(-1, 1)
b = np.random.uniform(-1, 1)

learning_rate = 0.7

for epoch in range(200):
    Y_Pred = W * X + b

    error = np.abs(Y_Pred - Y).mean()
    if error < 0.001:
        break

    # gradient descent 계산
    w_grad = learning_rate * ((Y_Pred - Y)*X).mean()
    b_grad = learning_rate * (Y_Pred - Y).mean()

    # W, b 값 갱신
    W = W - w_grad
    b = b - b_grad

    if epoch % 10 == 0:
        Y_pred = W * X + b
        plot_prediction(Y_Pred, Y)
```



![output_8_0](./img/gradient/output_8_0.png)





![output_8_1](./img/gradient/output_8_1.png)





![output_8_2](./img/gradient/output_8_2.png)





![output_8_3](./img/gradient/output_8_3.png)





![output_8_4](./img/gradient/output_8_4.png)





![output_8_5](./img/gradient/output_8_5.png)





![output_8_6](./img/gradient/output_8_6.png)





![output_8_7](./img/gradient/output_8_7.png)





![output_8_8](./img/gradient/output_8_8.png)





![output_8_9](./img/gradient/output_8_9.png)




```python

```
